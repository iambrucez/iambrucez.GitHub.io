<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Captionize | Yufan Zhang</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="icon" href="/favicon.ico">
  <link rel="canonical" href="/posts/captionize/" />
    
    
    <link rel="stylesheet" href="/css/style.min.e426ae586c69196ad5b6eac62c2e1f6e22632dc482e42bf694fe15e641af7fec.css">
    <link rel="stylesheet" href="/assets/css/extended.min.9729f28a5087b689b946e103d96abd63bfd37b1417effa251dbf798312e3fba5.css">

  
    <meta name="description" content="Automatic Caption Generation for Photorealistic Images and Scientific Data Visualizations"/>
    <meta property="og:title" content="Captionize"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="/posts/captionize/"/>
    <meta property="og:image" content="/images/captionize.jpg"/>
    <meta property="og:description" content="Automatic Caption Generation for Photorealistic Images and Scientific Data Visualizations"/>
    <meta name="twitter:card" content="summary"/>
    <meta name="twitter:site" content="@zerostaticio"/>
    <meta name="twitter:creator" content="@zerostaticio"/>
  

  
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=DM&#43;Mono&amp;family=DM&#43;Sans:ital,wght@0,400;0,500;0,700;1,400;1,500;1,700&amp;family=Space&#43;Grotesk:wght@300;500;700&amp;display=swap" rel="stylesheet">
  

  
</head>




<body class='page frame page-blog-single'>
  <div id="menu-main-mobile" class="menu-main-mobile">
    <ul class="menu">
        
        
            
                <li class="menu-item-home">
                    <a href="/">Home</a>
                </li>
            
        
            
                <li class="menu-item-projects">
                    <a href="/posts/">Projects</a>
                </li>
            
        
            
                <li class="menu-item-about">
                    <a href="/about/">About</a>
                </li>
            
        
    </ul>
</div>
  <div id="wrapper" class="wrapper">
    <div class='header'>
  <a class="header-logo" href="/">
    <img src="/images/black.png" alt="Logo" />
    
  </a>
  <div class="menu-main">
    <ul>
      
      
      
      
      <li class="menu-item-home ">
        <a href="/">
          
          <span>Home</span>
        </a>
      </li>
      
      
      
      <li class="menu-item-projects ">
        <a href="/posts/">
          
          <span>Projects</span>
        </a>
      </li>
      
      
      
      <li class="menu-item-about ">
        <a href="/about/">
          
          <span>About</span>
        </a>
      </li>
      
    </ul>
  </div>
  <div id="toggle-menu-main-mobile" class="hamburger-trigger">
    <button class="hamburger">Menu</button>
  </div>
</div>
    
  <div class="blog">
    
    <div class="intro">
      <h1>Captionize<span class="dot">.</span></h1>
      
      <img alt="captionize" src="/images/captionize.jpg" />
      
    </div>
    <div class="content">
      <p>Automatic Caption Generation for Photorealistic Images and Scientific Data Visualizations</p>
<h1 id="proposal">Proposal</h1>
<h2 id="motivation">Motivation</h2>
<p>Captioning images is a fundamental human ability where, within moments of seeing an image, we can generate a descriptive statement. For computers, however, the ability to accurately describe images is significantly more complex yet increasingly valuable. From aiding visually impaired individuals to streamlining images posting process in digital marketing, there&rsquo;s an endless array of applications. One niche yet crucial area of application is in the scientific community, where researchers grapple with the immense task of captioning myriad data visualizations and figures. This project aims to bridge this gap by developing a ready-to-use tool to generate relevant captions for both standard images and scientific visualizations.</p>
<h2 id="method">Method</h2>
<p>Our primary approach will be grounded in Deep Learning, leveraging the combined power of Convolutional Neural Networks (CNNs) for image feature extraction and the commonly used methods in Natural Language Processing (NLP) such as Long Short-Term Memory (LSTM) for sequential data processing to generate captions. Initially, we will utilize the existing and relatively small image-caption datasets such as the Flickr30k dataset to train a baseline model. Once established, we plan to either curate or utilize existing datasets of scientific visualizations to fine-tune our model, aiming for domain-specific accuracy. Additional techniques, like attention mechanisms, might be employed to ensure the model focuses on salient features in the images.</p>
<h2 id="experiments">Experiments</h2>
<ol>
<li>Baseline Model Evaluation: Using a traditional image-caption dataset, we will train and evaluate a baseline captioning model. Metrics such as BLEU will assess its performance.</li>
<li>Domain-specific Fine-tuning: Upon obtaining a pre-trained model, we&rsquo;ll fine-tune it using a dataset containing scientific visualizations, assessing how transfer learning impacts performance in this niche domain.</li>
<li>Comparison with Existing Tools: We will compare our generated captions with existing tools or manually generated captions to gauge relevance and accuracy.</li>
<li>User Study: We aim to build an interactive web application and recruit participants to test our tool in real-world scenarios, collecting feedback on its utility and users’ satisfaction.</li>
</ol>

    </div>
  </div>

    <div class="footer">
  <div class="footer-text">
    <p>© 2022-2023 <a href="https://yufanbruce.com">YufanBruce.com</a></p>
  </div>
</div>
  
  </div>

  

  
    <script type="text/javascript" src="/js/bundle.min.5993fcb11c07dea925a3fbd58c03c7f1857197c35fccce3aa963a12c0b3c9960.js"></script>
  

  
  

  
  
  
    
  

  

  

</body>
</html>