2:I[9275,[],""]
3:I[1343,[],""]
4:I[2224,["291","static/chunks/291-de708f65a06c2e3a.js","348","static/chunks/app/project/layout-d989c307148eeae6.js"],"default"]
5:I[1804,["185","static/chunks/app/layout-561c173eda5e1936.js"],"default"]
0:["YYik9LybV0uh4lnSsRzFx",[[["",{"children":["project",{"children":["mfnet",{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",{"children":["project",{"children":["mfnet",{"children":["__PAGE__",{},[["$L1",[["$","blockquote",null,{"children":["\n",["$","p",null,{"children":"\"Hmm, can Generative AI help us design fonts?”"}],"\n"]}],"\n",["$","p",null,{"children":[["$","a",null,{"href":"https://github.com/iamyufan/MF-Net","children":"[GitHub Repo]"}],"\n",["$","a",null,{"href":"https://doi.org/10.1145/3503161.3548414","children":"[DOI: 10.1145/3503161.3548414]"}],"\n",["$","a",null,{"href":"https://mfont.net/","children":"[Website]"}]]}],"\n",["$","p",null,{"children":["$","strong",null,{"children":"MF-Net: A Novel Few-shot Stylized Multilingual Font Generation Method"}]}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":["Paper presented at ",["$","a",null,{"href":"https://2022.acmmm.org/","children":"the 30th ACM International Conference on Multimedia (MM ‘22)"}]]}],"\n",["$","li",null,{"children":["Authors: ",["$","strong",null,{"children":["$","a",null,{"href":"https://yufanbruce.com","children":"Yufan Zhang"}]}],", ",["$","a",null,{"href":"https://junkaiman.com/","children":"Junkai Man"}],", ",["$","a",null,{"href":"https://scholars.duke.edu/person/Peng.Sun1","children":"Peng Sun"}],"*"]}],"\n"]}],"\n",["$","p",null,{"children":["$","strong",null,{"children":"Video Presentation"}]}],"\n",["$","iframe",null,{"width":"100%","height":"600px","src":"https://www.youtube.com/embed/YVkbaq7vZTA","title":"[ACM Multimedia 22] MF-Net: A Novel Few-shot Stylized Multilingual Font Generation Method","frameborder":"0","allow":"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share","allowfullscreen":true}],"\n",["$","hr",null,{}],"\n",["$","h2",null,{"children":"Introduction"}],"\n",["$","p",null,{"children":"Designing fonts is never a simple task, especially when it comes to non-Latin languages like Chinese, which have intricate glyph patterns and a high number of characters. Furthermore, in the real world, creating a multilingual font poses an even greater challenge, requiring years of research, expertise in using numerous professional tools, and collaboration among multiple font designers specializing in various languages. However, a multilingual typeface is indispensable for many applications, including multilingual websites, documents, and books. Therefore, it is crucial to develop a system that can automatically generate stylized multilingual fonts."}],"\n",["$","p",null,{"children":["In this project, I, together with my roommate, Junkai, and Prof. Peng Sun attempted to address this issue using deep learning techniques. Specifically, our study aimed to develop a highly effective ",["$","strong",null,{"children":"few-shot multilingual stylized font generator"}],". This generator would be capable of producing an entire font family in all ",["$","strong",null,{"children":"unseen languages"}]," that share the desired font style, given only a limited number of font images representing the target style from one language. Our work shows promise as it significantly reduces the cost associated with multilingual stylistic font design, enabling anyone to create their own fonts without years of extensive training."]}],"\n",["$","h2",null,{"children":"Methodology"}],"\n",["$","p",null,{"children":"Developing such an intelligent system faces three significant obstacles:"}],"\n",["$","ol",null,{"children":["\n",["$","li",null,{"children":[["$","strong",null,{"children":"Few-shot learning"}],": The system must learn the font style from a small number of reference samples. This means it needs to quickly grasp the characteristics of the desired style and generate accurate results with limited training data."]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Font style transfer between multiple languages"}],": The system should be capable of transferring font styles across different languages, even for languages that it hasn't been explicitly trained on. This requires the ability to capture the essence of the style and apply it appropriately to various linguistic systems."]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Output generation by direct inference"}],": Instead of relying on model fine-tuning, the system aims to generate the desired output directly through inference. This approach reduces the need for extensive fine-tuning and allows for more efficient font generation."]}],"\n"]}],"\n",["$","p",null,{"children":["$","img",null,{"src":"https://github.com/iamyufan/MF-Net/blob/main/img/1_overall.png?raw=true","alt":"Network Architecture"}]}],"\n",["$","p",null,{"children":["$","em",null,{"children":"Overview of the network structure of MF-Net"}]}],"\n",["$","p",null,{"children":["We introduced an end-to-end model based on a ",["$","strong",null,{"children":"generative adversarial network (GAN)"}]," to tackle these challenges. Specifically, the model incorporates two separate encoders within the generator to separate the content and style information of each font image. Taking inspiration from a paper published in ICCV '21, I proposed a unique skip connection called the ",["$","code",null,{"children":"language complexity-aware skip connection"}]," for our cross-language font generation task, as both studies aim to achieve style migration across multiple style domains. This innovative skip connection allows for adaptive preservation of the structural information of the content. Additionally, I made modifications to the loss function to ensure the decoupling of information by enforcing the distinct roles of the two encoders."]}],"\n",["$","h2",null,{"children":"Results Gallery"}],"\n",["$","p",null,{"children":["$","img",null,{"src":"https://github.com/iamyufan/MF-Net/raw/main/img/4_seen_lan_vis.png?raw=true","alt":"Results Gallery 1"}]}],"\n",["$","p",null,{"children":["$","em",null,{"children":"Results of MF-Net on seen languages"}]}],"\n",["$","p",null,{"children":["$","img",null,{"src":"https://github.com/iamyufan/MF-Net/raw/main/img/5_unseen_lan_vis.png?raw=true","alt":"Results Gallery 2"}]}],"\n",["$","p",null,{"children":["$","em",null,{"children":"Results of MF-Net on unseen languages"}]}],"\n",["$","h2",null,{"children":"Cite Us"}],"\n",["$","pre",null,{"children":["$","code",null,{"className":"language-latex","children":"@inproceedings{10.1145/3503161.3548414,\n   author = {Zhang, Yufan and Man, Junkai and Sun, Peng},\n   title = {MF-Net: A Novel Few-Shot Stylized Multilingual Font Generation Method},\n   year = {2022},\n   isbn = {9781450392037},\n   publisher = {Association for Computing Machinery},\n   address = {New York, NY, USA},\n   url = {https://doi.org/10.1145/3503161.3548414},\n   doi = {10.1145/3503161.3548414},\n   booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},\n   pages = {2088–2096},\n   numpages = {9},\n   keywords = {font design, image synthesis, few-shot learning, style transfer},\n   location = {Lisboa, Portugal},\n   series = {MM '22}\n}\n"}]}]]],null],null]},["$","$L2",null,{"parallelRouterKey":"children","segmentPath":["children","project","children","mfnet","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","$L4",null,{"children":["$","$L2",null,{"parallelRouterKey":"children","segmentPath":["children","project","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],"params":{}}],null],null]},[["$","html",null,{"lang":"en","className":"__className_587f35","children":["$","$L5",null,{"children":[["$","head",null,{}],["$","body",null,{"children":["$","$L2",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[],"styles":[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/355ab0295adb49e5.css","precedence":"next","crossOrigin":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/_next/static/css/1d22a85a77cfb8b7.css","precedence":"next","crossOrigin":"$undefined"}]]}]}]]}]}],null],null],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/493015e455655cf7.css","precedence":"next","crossOrigin":"$undefined"}]],"$L6"]]]]
6:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Yufan Zhang"}],["$","meta","3",{"name":"description","content":"Yufan Zhang's personal website"}],["$","link","4",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"16x16"}],["$","meta","5",{"name":"next-size-adjust"}]]
1:null
